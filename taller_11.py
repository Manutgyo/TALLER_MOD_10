# -*- coding: utf-8 -*-
"""Taller_11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1npgXxRihb159eFCjmDcWwUyFxCF-HGvp

Entrega Taller Módulo 11  ----- Nombre: Manuela Tamayo Garcia
"""

pip install sodapy

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sodapy import Socrata
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

client = Socrata("www.datos.gov.co", None)
results = client.get("u8ud-84pb")
df = pd.DataFrame.from_records(results)
df = df.sort_values("_3_tama_o_de_empresa")
df = df.set_index("_3_tama_o_de_empresa")
#Se eliminan todos los valores en el índice que sean iguales a "No aplica". De 1000 datos quedan 487
df = df.drop(["_2_sexo"], axis=1)
df = df.drop(["No aplica"], axis=0)

#Cambiar Tipo de empresa (Gran empresa, Mediana empresa, micro y pequeña a valores del 1-4)
tipo_empresa = list(df.index)
tipo_empresa_num = list()
for i in tipo_empresa:
    if i == "Gran empresa":
        i = 1
        tipo_empresa_num.append(i)
    elif i == "Mediana empresa":
        i = 2
        tipo_empresa_num.append(i)
    elif i == "Microempresa":
        i = 3
        tipo_empresa_num.append(i)
    else:
        i = 4
        tipo_empresa_num.append(i)
print(tipo_empresa)
tipo_empresa_num = np.array(tipo_empresa_num)
print(tipo_empresa_num)

#Cambiar los tipos de producto a valores del 1 al 23
producto = list(df["_6_producto_de_cr_dito"])
dic_producto = dict()
x = 0
for i in producto:
    if i not in dic_producto:
        x = x +1
    dic_producto[i]=dic_producto.get(i,x)
df.replace(dic_producto, inplace= True)

#Separar las listas que sirvan
producto_num = np.array(list(df["_6_producto_de_cr_dito"]))
tasa = np.array(list(df["_8_tasa_efectiva_promedio"]))
tasa = tasa.astype(float)
cod_banco = np.array(list(df["codigoentidad"]))
cod_banco = cod_banco.astype(int)
montos = np.array(list(df["_10_montos_desembolsados"]))
montos = montos.astype(float)

#Creación de un Nuevo Dataframe
elementos = {"Tipo de empresa":tipo_empresa_num, "Codigo Entidad Bancaria":cod_banco, "Tipo de producto": producto_num,
             "Tasa": tasa, "Montos desembolsados": montos}
nuevo_df = pd.DataFrame(elementos)
nuevo_df.describe()

#Aplicación del modelo KNN
x = nuevo_df[["Codigo Entidad Bancaria", "Tipo de producto", "Tasa", "Montos desembolsados"]].values
y = nuevo_df["Tipo de empresa"]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.15, random_state=0)
knn = KNeighborsClassifier(n_neighbors=4)
knn.fit(x_train, y_train)
prueba_modelo =knn.predict(x_test)
score = knn.score(x_test, y_test)
print("Score de validación:", score)

pred = knn.predict(x_test)
print(confusion_matrix(y_test, pred))
print(classification_report(y_test, pred))

"""Como se puede ver en los resultados anteriores, el KNN no clasificó bien los datos, se obtuvo un puntaje de acierto del 32%, lo que quiere decir que en promedio, de 10 intentos, erra 7. Los motivos detrás del error pueden deberse a la naturaleza de los datos, que, a pesar de que si existan categorías con base en los tamaños de empresa, pueden no ser suficientes para clasificar en categorías los tipos de empresa. Como se ve en la matriz de confusión y el reporte de clasificación, el mayor porcentaje de acierto, que aún sigue siendo insuficiente, pero superior a los demás, fue para agrupar las empresas de clasificación 3 (Microempresas) con un puntaje del 49%; para los demás grupos obtuvo resultados por debajo del 30%."""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.15, random_state=1)
knn = KNeighborsClassifier(n_neighbors=4)
knn.fit(x_train, y_train)
prueba_modelo =knn.predict(x_test)
score = knn.score(x_test, y_test)
print("Score de validación:", score)

pred = knn.predict(x_test)
print(confusion_matrix(y_test, pred))
print(classification_report(y_test, pred))

"""Sin embargo, vale la pena resaltar que, tras usar diferentes semillas, se notó un mejor comportamiento y un mejor resultado cuando la semilla se establecía en 1 o 2. Disminuye el porcentaje de acierto del grupo 3, pero incrementa en promedio un 10% en los demás."""

#PUNTO 2
#Importación de librerías necesarias
from sklearn.cluster import KMeans
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sb
from sklearn.preprocessing import MinMaxScaler

client2 = Socrata("www.datos.gov.co", None)
results2 = client2.get("4hzx-66uh")
df2 = pd.DataFrame.from_records(results2)

escuela = list(df2["esceula_de_formacion"])
dic_escuela = dict()
x = 0
for i in escuela:
    if i not in dic_escuela:
        x = x +1
    dic_escuela[i]=dic_escuela.get(i,x)
print(dic_escuela)
df2.replace(dic_escuela, inplace= True)
escuela = list(df2["esceula_de_formacion"])

estrato = np.array(list(df2["estrato"]))
estrato = list(estrato.astype(int))
#print(estrato)

escolarizacion = list(df2["escolarizado"])
dic_escolarizado = dict()
x = 0
for i in escolarizacion:
    if i not in dic_escolarizado:
        x = x +1
    dic_escolarizado[i]=dic_escolarizado.get(i,x)
print(dic_escolarizado)
df2.replace(dic_escolarizado, inplace= True)
escolarizacion = list(df2["escolarizado"])

regimen_salud = list(df2["regimen_de_salud"])
dic_regimen = dict()
x = 0
for i in regimen_salud:
    if i not in dic_regimen:
        x = x +1
    dic_regimen[i]=dic_regimen.get(i,x)
print(dic_regimen)
df2.replace(dic_regimen, inplace= True)
regimen_salud = list(df2["regimen_de_salud"])

edad = np.array(list(df2["edad_a_os"]))
edad = list(edad.astype(int))

nivel_escolaridad = list(df2["nivel_de_escolaridad"])
dic_escolaridad = dict()
x = 0
for i in nivel_escolaridad:
    if i not in dic_escolaridad:
        x = x +1
    dic_escolaridad[i]=dic_escolaridad.get(i,x)
dic_escolaridad["SECUNDARIA"] = 2
dic_escolaridad["PRIMARIA"]= 1
print(dic_escolaridad)
df2.replace(dic_escolaridad, inplace= True)
nivel_escolaridad = list(df2["nivel_de_escolaridad"])

#Creación de un nuevo dataset
elementos2 = {"Estrato": estrato, "Escuela de formación": escuela, "Edad": edad,
             "Nivel de escolaridad": nivel_escolaridad, "Escolarizado": escolarizacion,"Regimen de salud": regimen_salud}
nuevo_df2 = pd.DataFrame(elementos2)

#Identificar distribución del DF según el tipo de estrato
categorias = nuevo_df2.groupby('Estrato').size()
nuevo_df2 = nuevo_df2.drop("Estrato", axis=1)

#Definición de parámetros
inercias = list()
x1 = np.array(nuevo_df2[["Escuela de formación", "Edad", "Nivel de escolaridad", "Escolarizado", "Regimen de salud"]])
print(x1.shape)

#Calculando los K necesarios (Grupos necesarios) con el gráfico del codo
for i in range (1,10):
    kmeans = KMeans(n_clusters=i, max_iter=300, n_init=10)
    kmeans.fit(x1)
    inercias.append(kmeans.inertia_)

plt.plot(range(1,10), inercias)
plt.xlabel("Clusters")
plt.ylabel("Inercia")
plt.title("Curva del codo")
plt.show()

"""Se escogen clusters de entre 4-5 basado en la gráfica anterior"""

#Aplicación del modelo
escalador = MinMaxScaler().fit(nuevo_df2.values)
nuevo_df2 = pd.DataFrame(escalador.transform(nuevo_df2.values),
                         columns=["Escuela de formación", "Edad", "Nivel de escolaridad", "Escolarizado", "Regimen de salud"])
print(nuevo_df2)
kmeans = KMeans(n_clusters=5)
objetivo = kmeans.fit_predict(nuevo_df2.values)
cluster = kmeans.labels_
#Asignar clusters, centroides e inercias finales
nuevo_df2["cluster"] =cluster
centroides = kmeans.cluster_centers_
inercia_final= kmeans.inertia_

#Gráficos
fig=plt.figure()
ax=fig.add_subplot(111,projection='3d')
ax.scatter(nuevo_df2.values[objetivo==0,0],nuevo_df2.values[objetivo==0,4],nuevo_df2.values[objetivo==0,3],nuevo_df2.values[objetivo==0,2],
           s=nuevo_df2.values[objetivo==0,1],color='green')

ax.scatter(nuevo_df2.values[objetivo==1,0],nuevo_df2.values[objetivo==1,4],nuevo_df2.values[objetivo==1,3],nuevo_df2.values[objetivo==1,2],
           s=nuevo_df2.values[objetivo==1,1],color='red', marker='o')

ax.scatter(nuevo_df2.values[objetivo==2,0],nuevo_df2.values[objetivo==2,4],nuevo_df2.values[objetivo==2,3],nuevo_df2.values[objetivo==2,2],
           s=nuevo_df2.values[objetivo==2,1],color='blue', marker='s')

ax.scatter(nuevo_df2.values[objetivo==3,0],nuevo_df2.values[objetivo==3,4],nuevo_df2.values[objetivo==3,3],nuevo_df2.values[objetivo==3,2],
           s=nuevo_df2.values[objetivo==3,1],color='blue', marker='s')

ax.scatter(nuevo_df2.values[objetivo==4,0],nuevo_df2.values[objetivo==4,4], nuevo_df2.values[objetivo==4,3],nuevo_df2.values[objetivo==4,2],
           s=nuevo_df2.values[objetivo==4,1],color='blue', marker='s')
#x.cluster_centers
ax.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,3],
          kmeans.cluster_centers_[:,2], s=35, color='black', marker='X')

plt.show()

plt.figure()

colores = ["red", "blue", "orange", "black", "purple"]

n_cluster = kmeans.n_clusters

for i in range(n_cluster):
    plt.scatter(nuevo_df2[nuevo_df2["cluster"] == i]["cluster"], nuevo_df2[nuevo_df2["cluster"] == i]["Edad"], c = colores[i])
    plt.scatter(nuevo_df2[nuevo_df2["cluster"] == i]["cluster"], nuevo_df2[nuevo_df2["cluster"] == i]["Escuela de formación"], c = colores[i])
    plt.scatter(nuevo_df2[nuevo_df2["cluster"] == i]["cluster"], nuevo_df2[nuevo_df2["cluster"] == i]["Escolarizado"], c = colores[i])
    plt.scatter(nuevo_df2[nuevo_df2["cluster"] == i]["cluster"], nuevo_df2[nuevo_df2["cluster"] == i]["Regimen de salud"], c = colores[i])
    plt.scatter(nuevo_df2[nuevo_df2["cluster"] == i]["cluster"], nuevo_df2[nuevo_df2["cluster"] == i]["Nivel de escolaridad"], c = colores[i])

plt.show()

#Inercia
print(inercia_final)

"""En los gráficos y en la inercia final se puede identificar que la agrupación no fue la más adecuada, tiene una inercia muy alta, superior a 100, y se ve que hay unos puntos que se alejan del grupo pero siguen siendo seleccionados a pesar de que se alejen de su centro."""